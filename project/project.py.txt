import matplotlib.pyplot as plt
import seaborn as sns
from keras.models import Sequential
from sklearn.preprocessing import LabelEncoder
from keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

import math
import numpy as np
import pandas as pd
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

seed=0
np.random.seed(seed)
tf.set_random_seed(seed)

df=pd.read_csv("analysis_datasets/framingham_.csv")
print(df.shape)

# 1. 중복데이터 삭제하기
data = df.drop_duplicates(subset=None, keep='first', inplace=False)
print(data.shape)
print()

# 2. 존재하는 행 갯수와 타입을 확인한다.
print(data.info())
print()

# 3. NaN값이 몇개가 있는지 확인한다.
print(data.isnull().sum())
print()

# 4. NaN값 제거하기  -> 0으로 채우기
data=data.replace(to_replace=np.NaN,value=0)

print(data.isnull().sum())
print(data.shape)

x = data.iloc[:4241,0:15]
y = data.iloc[:4241,15]

train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.3,random_state=seed)
print(y)

model=Sequential()   # 딥러닝 구조를 짜고 층을 설정하는 부분.

model.add(Dense(35,input_dim=15,activation='relu'))
model.add(Dense(15,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

model.fit(train_x,train_y,epochs=100,batch_size=4)

print("Accuracy : %.4f"%(model.evaluate(test_x,test_y)[1]))

corr = data.corr()
plt.figure(figsize=(14,10))
           
#상관관계 -1부터 1까지 
corrs = data.corr(method='pearson')
plt.figure(figsize=(20, 20))

mask = np.zeros_like(corrs, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

sns.heatmap(corrs, annot=True, cmap="RdYlBu_r",cbar_kws={"shrink": .5}, mask=mask, vmin = -1,vmax = 1 )
plt.show()
print(corrs['TenYearCHD']) 

data=data.drop(['education'],axis=1,inplace=False)

x_ = data.iloc[:4241,0:14]
y_ = data.iloc[:4241,14]

train_x1,test_x1,train_y1,test_y1 = train_test_split(x_,y_,test_size=0.3,random_state=seed)

edit_model=Sequential()   # 딥러닝 구조를 짜고 층을 설정하는 부분.

edit_model.add(Dense(35,input_dim=14,activation='relu'))
edit_model.add(Dense(14,activation='relu'))
edit_model.add(Dense(1,activation='sigmoid'))

edit_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

history = edit_model.fit(train_x1,train_y1,epochs=100,batch_size=4)
print("Accuracy : %.4f"%(edit_model.evaluate(test_x1,test_y1)[1]))

import sklearn as skl
from sklearn.datasets import make_classification
from sklearn import preprocessing
from sklearn import svm
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn import metrics
from tempfile import mkdtemp
from shutil import rmtree

def plot_roc(y_test, y_pred):
       fpr, tpr, thresholds = skl.metrics.roc_curve(y_test, y_pred, pos_label=1)
       roc_auc = skl.metrics.auc(fpr, tpr)
       plt.figure()
        
       lw = 2
       plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area ={0:.2f})'.format(roc_auc))
       plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
    
       plt.xlim([0.0, 1.0])
       plt.ylim([0.0, 1.05])
    
       plt.xlabel('False Positive Rate')
       plt.ylabel('True Positive Rate')
    
       plt.title('Receiver operating characteristic example')
       plt.legend(loc="lower right")
       plt.show()

y_hat= edit_model.predict(x_)
y_hat=(y_hat>0.5)
cm = confusion_matrix(y_, y_hat)
loss, accuracy = edit_model.evaluate(x_,y_)
print('Loss : ', loss)
print('Accuracy : ', accuracy)
print('Confusion Matrix : \n', cm)

plot_roc(y_,y_hat)